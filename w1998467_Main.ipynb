{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f18f970",
   "metadata": {},
   "source": [
    "1. Importing Admissions and Patients CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7c3f6440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject_id gender  anchor_age  anchor_year anchor_year_group        dod\n",
      "0    10000032      F          52         2180       2014 - 2016   9/9/2180\n",
      "1    10000048      F          23         2126       2008 - 2010        NaN\n",
      "2    10000058      F          33         2168       2020 - 2022        NaN\n",
      "3    10000068      F          19         2160       2008 - 2010        NaN\n",
      "4    10000084      M          72         2160       2017 - 2019  2/13/2161\n",
      "5    10000102      F          27         2136       2008 - 2010        NaN\n",
      "6    10000108      M          25         2163       2014 - 2016        NaN\n",
      "7    10000115      M          24         2154       2017 - 2019        NaN\n",
      "8    10000117      F          48         2174       2008 - 2010        NaN\n",
      "9    10000161      M          60         2163       2020 - 2022        NaN\n",
      "   subject_id   hadm_id        admittime         dischtime deathtime  \\\n",
      "0    10000032  22595853   5/6/2180 22:23    5/7/2180 17:15       NaN   \n",
      "1    10000032  22841357  6/26/2180 18:27   6/27/2180 18:49       NaN   \n",
      "2    10000032  25742920   8/5/2180 23:44    8/7/2180 17:50       NaN   \n",
      "3    10000032  29079034  7/23/2180 12:35   7/25/2180 17:55       NaN   \n",
      "4    10000068  25022803   3/3/2160 23:16     3/4/2160 6:26       NaN   \n",
      "5    10000084  23052089  11/21/2160 1:56  11/25/2160 14:52       NaN   \n",
      "6    10000084  29888819  12/28/2160 5:11  12/28/2160 16:07       NaN   \n",
      "7    10000108  27250926  9/27/2163 23:17    9/28/2163 9:04       NaN   \n",
      "8    10000117  22927623  11/15/2181 2:05  11/15/2181 14:52       NaN   \n",
      "9    10000117  27988844  9/18/2183 18:10   9/21/2183 16:30       NaN   \n",
      "\n",
      "      admission_type admit_provider_id      admission_location  \\\n",
      "0             URGENT            P49AFC  TRANSFER FROM HOSPITAL   \n",
      "1           EW EMER.            P784FA          EMERGENCY ROOM   \n",
      "2           EW EMER.            P19UTS          EMERGENCY ROOM   \n",
      "3           EW EMER.            P06OTX          EMERGENCY ROOM   \n",
      "4     EU OBSERVATION            P39NWO          EMERGENCY ROOM   \n",
      "5           EW EMER.            P42H7G   WALK-IN/SELF REFERRAL   \n",
      "6     EU OBSERVATION            P35NE4      PHYSICIAN REFERRAL   \n",
      "7     EU OBSERVATION            P40JML          EMERGENCY ROOM   \n",
      "8     EU OBSERVATION            P47EY8          EMERGENCY ROOM   \n",
      "9  OBSERVATION ADMIT            P13ACE   WALK-IN/SELF REFERRAL   \n",
      "\n",
      "  discharge_location insurance language marital_status   race  \\\n",
      "0               HOME  Medicaid  English        WIDOWED  WHITE   \n",
      "1               HOME  Medicaid  English        WIDOWED  WHITE   \n",
      "2            HOSPICE  Medicaid  English        WIDOWED  WHITE   \n",
      "3               HOME  Medicaid  English        WIDOWED  WHITE   \n",
      "4                NaN       NaN  English         SINGLE  WHITE   \n",
      "5   HOME HEALTH CARE  Medicare  English        MARRIED  WHITE   \n",
      "6                NaN  Medicare  English        MARRIED  WHITE   \n",
      "7                NaN       NaN  English         SINGLE  WHITE   \n",
      "8                NaN  Medicaid  English       DIVORCED  WHITE   \n",
      "9   HOME HEALTH CARE  Medicaid  English       DIVORCED  WHITE   \n",
      "\n",
      "          edregtime         edouttime  hospital_expire_flag  \n",
      "0    5/6/2180 19:17    5/6/2180 23:30                     0  \n",
      "1   6/26/2180 15:54   6/26/2180 21:31                     0  \n",
      "2    8/5/2180 20:58     8/6/2180 1:44                     0  \n",
      "3    7/23/2180 5:54   7/23/2180 14:00                     0  \n",
      "4    3/3/2160 21:55     3/4/2160 6:26                     0  \n",
      "5  11/20/2160 20:36   11/21/2160 3:20                     0  \n",
      "6  12/27/2160 18:32  12/28/2160 16:07                     0  \n",
      "7   9/27/2163 16:18    9/28/2163 9:04                     0  \n",
      "8  11/14/2181 21:51   11/15/2181 9:57                     0  \n",
      "9    9/18/2183 8:41   9/18/2183 20:20                     0  \n",
      "   subject_id   hadm_id        admittime        dischtime deathtime  \\\n",
      "0    10000032  22595853   5/6/2180 22:23   5/7/2180 17:15       NaN   \n",
      "1    10000032  22841357  6/26/2180 18:27  6/27/2180 18:49       NaN   \n",
      "2    10000032  25742920   8/5/2180 23:44   8/7/2180 17:50       NaN   \n",
      "3    10000032  29079034  7/23/2180 12:35  7/25/2180 17:55       NaN   \n",
      "4    10000068  25022803   3/3/2160 23:16    3/4/2160 6:26       NaN   \n",
      "\n",
      "   admission_type admit_provider_id      admission_location  \\\n",
      "0          URGENT            P49AFC  TRANSFER FROM HOSPITAL   \n",
      "1        EW EMER.            P784FA          EMERGENCY ROOM   \n",
      "2        EW EMER.            P19UTS          EMERGENCY ROOM   \n",
      "3        EW EMER.            P06OTX          EMERGENCY ROOM   \n",
      "4  EU OBSERVATION            P39NWO          EMERGENCY ROOM   \n",
      "\n",
      "  discharge_location insurance  ... marital_status   race        edregtime  \\\n",
      "0               HOME  Medicaid  ...        WIDOWED  WHITE   5/6/2180 19:17   \n",
      "1               HOME  Medicaid  ...        WIDOWED  WHITE  6/26/2180 15:54   \n",
      "2            HOSPICE  Medicaid  ...        WIDOWED  WHITE   8/5/2180 20:58   \n",
      "3               HOME  Medicaid  ...        WIDOWED  WHITE   7/23/2180 5:54   \n",
      "4                NaN       NaN  ...         SINGLE  WHITE   3/3/2160 21:55   \n",
      "\n",
      "         edouttime hospital_expire_flag  gender anchor_age  anchor_year  \\\n",
      "0   5/6/2180 23:30                    0       F         52         2180   \n",
      "1  6/26/2180 21:31                    0       F         52         2180   \n",
      "2    8/6/2180 1:44                    0       F         52         2180   \n",
      "3  7/23/2180 14:00                    0       F         52         2180   \n",
      "4    3/4/2160 6:26                    0       F         19         2160   \n",
      "\n",
      "   anchor_year_group       dod  \n",
      "0        2014 - 2016  9/9/2180  \n",
      "1        2014 - 2016  9/9/2180  \n",
      "2        2014 - 2016  9/9/2180  \n",
      "3        2014 - 2016  9/9/2180  \n",
      "4        2008 - 2010       NaN  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#reading the patients and admissions csv\n",
    "patients = pd.read_csv(\"patients.csv/patients.csv\")\n",
    "admissions = pd.read_csv(\"admissions.csv/admissions.csv\")\n",
    "\n",
    "print(patients.head(10))\n",
    "print(admissions.head(10))\n",
    "\n",
    "#merging the patients.csv and admission.csv based on subject_id\n",
    "df = admissions.merge(patients, on=\"subject_id\", how=\"left\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9db5a47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject_id   hadm_id         transfertime prev_service curr_service\n",
      "0    10000032  22595853  2180-05-06 22:24:57          NaN          MED\n",
      "1    10000032  22841357  2180-06-26 18:28:08          NaN          MED\n",
      "2    10000032  25742920  2180-08-05 23:44:50          NaN          MED\n",
      "3    10000032  29079034  2180-07-23 12:36:04          NaN          MED\n",
      "4    10000068  25022803  2160-03-03 23:17:17          NaN          MED\n",
      "(593071, 5)\n",
      "   subject_id   hadm_id        admittime        dischtime deathtime  \\\n",
      "0    10000032  22595853   5/6/2180 22:23   5/7/2180 17:15       NaN   \n",
      "1    10000032  22841357  6/26/2180 18:27  6/27/2180 18:49       NaN   \n",
      "2    10000032  25742920   8/5/2180 23:44   8/7/2180 17:50       NaN   \n",
      "3    10000032  29079034  7/23/2180 12:35  7/25/2180 17:55       NaN   \n",
      "4    10000068  25022803   3/3/2160 23:16    3/4/2160 6:26       NaN   \n",
      "\n",
      "   admission_type admit_provider_id      admission_location  \\\n",
      "0          URGENT            P49AFC  TRANSFER FROM HOSPITAL   \n",
      "1        EW EMER.            P784FA          EMERGENCY ROOM   \n",
      "2        EW EMER.            P19UTS          EMERGENCY ROOM   \n",
      "3        EW EMER.            P06OTX          EMERGENCY ROOM   \n",
      "4  EU OBSERVATION            P39NWO          EMERGENCY ROOM   \n",
      "\n",
      "  discharge_location insurance  ...        edouttime hospital_expire_flag  \\\n",
      "0               HOME  Medicaid  ...   5/6/2180 23:30                    0   \n",
      "1               HOME  Medicaid  ...  6/26/2180 21:31                    0   \n",
      "2            HOSPICE  Medicaid  ...    8/6/2180 1:44                    0   \n",
      "3               HOME  Medicaid  ...  7/23/2180 14:00                    0   \n",
      "4                NaN       NaN  ...    3/4/2160 6:26                    0   \n",
      "\n",
      "  gender anchor_age anchor_year  anchor_year_group       dod  \\\n",
      "0      F         52        2180        2014 - 2016  9/9/2180   \n",
      "1      F         52        2180        2014 - 2016  9/9/2180   \n",
      "2      F         52        2180        2014 - 2016  9/9/2180   \n",
      "3      F         52        2180        2014 - 2016  9/9/2180   \n",
      "4      F         19        2160        2008 - 2010       NaN   \n",
      "\n",
      "          transfertime  prev_service curr_service  \n",
      "0  2180-05-06 22:24:57           NaN          MED  \n",
      "1  2180-06-26 18:28:08           NaN          MED  \n",
      "2  2180-08-05 23:44:50           NaN          MED  \n",
      "3  2180-07-23 12:36:04           NaN          MED  \n",
      "4  2160-03-03 23:17:17           NaN          MED  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "Missing curr_service: 16\n"
     ]
    }
   ],
   "source": [
    "# reading services csv\n",
    "services = pd.read_csv(\"services.csv/services.csv\")\n",
    "\n",
    "print(services.head())\n",
    "print(services.shape)\n",
    "\n",
    "#merging curr_service into main dataframe\n",
    "df = df.merge(\n",
    "    services,\n",
    "    on=[\"subject_id\", \"hadm_id\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(df.head())\n",
    "print(\"Missing curr_service:\", df[\"curr_service\"].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d5cccb",
   "metadata": {},
   "source": [
    "2. Importing the diagnoses_icd csv and filtering only for MI patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d59a45af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Myocardial Infarction ICD codes: ['41000', '41001', '41002', '41010', '41011', '41012', '41020', '41021', '41022', '41030', '41031', '41032', '41040', '41041', '41042', '41050', '41051', '41052', '41060', '41061', '41062', '41070', '41071', '41072', '41080', '41081', '41082', '41090', '41091', '41092', 'I21', 'I210', 'I2101', 'I2102', 'I2109', 'I211', 'I2111', 'I2119', 'I212', 'I2121', 'I2129', 'I213', 'I214', 'I219', 'I21A', 'I21A1', 'I21A9', 'I22', 'I220', 'I221', 'I222', 'I228', 'I229']\n",
      "\n",
      " mi_diagnoses\n",
      "   subject_id   hadm_id  seq_num icd_code  icd_version\n",
      "0    10000764  27897940        2    41071            9\n",
      "1    10000980  26913865        1    41071            9\n",
      "2    10001492  27463908        1    41071            9\n",
      "3    10002013  24760295        1    41071            9\n",
      "4    10002155  23822395        1    41011            9\n",
      "MI diagnosis rows: 16829\n",
      "Unique patients: 13152\n",
      "Unique admissions: 16537\n",
      "(16829, 5)\n",
      "\n",
      "    subject_id   hadm_id         admittime         dischtime deathtime  \\\n",
      "0    10000764  27897940  10/14/2132 23:31  10/19/2132 16:30       NaN   \n",
      "1    10000980  26913865    6/27/2189 7:38     7/3/2189 3:00       NaN   \n",
      "2    10000980  26913865    6/27/2189 7:38     7/3/2189 3:00       NaN   \n",
      "3    10001492  27463908   9/23/2136 18:02   9/25/2136 17:45       NaN   \n",
      "4    10002013  24760295   7/10/2160 19:33   7/12/2160 12:30       NaN   \n",
      "5    10002155  23822395    8/4/2129 12:44   8/18/2129 16:53       NaN   \n",
      "6    10002155  23822395    8/4/2129 12:44   8/18/2129 16:53       NaN   \n",
      "7    10002495  24982426   5/22/2141 20:17   5/29/2141 17:41       NaN   \n",
      "8    10002667  23197839   2/23/2187 16:01   2/28/2187 16:00       NaN   \n",
      "9    10003417  27053320    1/2/2111 19:21    1/9/2111 16:20       NaN   \n",
      "\n",
      "      admission_type admit_provider_id      admission_location  \\\n",
      "0             URGENT            P38YR6  TRANSFER FROM HOSPITAL   \n",
      "1           EW EMER.            P06OTX          EMERGENCY ROOM   \n",
      "2           EW EMER.            P06OTX          EMERGENCY ROOM   \n",
      "3           EW EMER.            P1969S          EMERGENCY ROOM   \n",
      "4           EW EMER.            P67G26          EMERGENCY ROOM   \n",
      "5           EW EMER.            P81FQT          PROCEDURE SITE   \n",
      "6           EW EMER.            P81FQT          PROCEDURE SITE   \n",
      "7             URGENT            P336JM  TRANSFER FROM HOSPITAL   \n",
      "8  OBSERVATION ADMIT            P95BQY      PHYSICIAN REFERRAL   \n",
      "9  OBSERVATION ADMIT            P68D28   WALK-IN/SELF REFERRAL   \n",
      "\n",
      "             discharge_location insurance  ...         edouttime  \\\n",
      "0              HOME HEALTH CARE  Medicare  ...  10/15/2132 16:45   \n",
      "1              HOME HEALTH CARE  Medicare  ...    6/27/2189 8:42   \n",
      "2              HOME HEALTH CARE  Medicare  ...    6/27/2189 8:42   \n",
      "3                          HOME  Medicare  ...   9/23/2136 19:02   \n",
      "4                          HOME  Medicare  ...   7/10/2160 20:37   \n",
      "5  CHRONIC/LONG TERM ACUTE CARE  Medicare  ...    8/4/2129 12:35   \n",
      "6  CHRONIC/LONG TERM ACUTE CARE  Medicare  ...    8/4/2129 12:35   \n",
      "7      SKILLED NURSING FACILITY  Medicare  ...               NaN   \n",
      "8              HOME HEALTH CARE   Private  ...               NaN   \n",
      "9              HOME HEALTH CARE  Medicaid  ...    1/2/2111 22:49   \n",
      "\n",
      "  hospital_expire_flag gender anchor_age anchor_year  anchor_year_group  \\\n",
      "0                    0      M         86        2132        2014 - 2016   \n",
      "1                    0      F         73        2186        2008 - 2010   \n",
      "2                    0      F         73        2186        2008 - 2010   \n",
      "3                    0      F         71        2136        2008 - 2010   \n",
      "4                    0      F         53        2156        2008 - 2010   \n",
      "5                    0      F         80        2128        2008 - 2010   \n",
      "6                    0      F         80        2128        2008 - 2010   \n",
      "7                    0      M         81        2141        2014 - 2016   \n",
      "8                    0      F         58        2187        2020 - 2022   \n",
      "9                    0      M         91        2111        2020 - 2022   \n",
      "\n",
      "         dod         transfertime  prev_service curr_service  \n",
      "0        NaN  2132-10-14 23:32:59           NaN          MED  \n",
      "1  8/26/2193  2189-06-27 07:40:38           NaN          MED  \n",
      "2  8/26/2193  2189-07-03 09:25:28           MED         CMED  \n",
      "3        NaN  2136-09-23 18:02:40           NaN          MED  \n",
      "4        NaN  2160-07-10 19:34:13           NaN         CMED  \n",
      "5  3/10/2131  2129-08-04 12:45:00           NaN         CMED  \n",
      "6  3/10/2131  2129-08-16 15:39:21          CMED         OMED  \n",
      "7        NaN  2141-05-22 20:18:01           NaN         CMED  \n",
      "8        NaN  2187-02-23 16:02:25           NaN        CSURG  \n",
      "9        NaN  2111-01-02 19:22:08           NaN          MED  \n",
      "\n",
      "[10 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "#reading the d_icd_diagnoses csv to identify MI related ICD codes\n",
    "d_icd = pd.read_csv(\"d_icd_diagnoses.csv/d_icd_diagnoses.csv\", dtype={\"icd_code\": \"string\"})\n",
    "\n",
    "#filtering only MI-related ICD-9 and ICD-10 codes\n",
    "icd9_mi = d_icd[(d_icd[\"icd_version\"] == 9) & (d_icd[\"icd_code\"].str.startswith(\"410\")) & (d_icd[\"icd_code\"].str.len() == 5)]\n",
    "icd10_mi = d_icd[(d_icd[\"icd_version\"] == 10) &(d_icd[\"icd_code\"].str.startswith((\"I21\", \"I22\")))]\n",
    "\n",
    "#combining ICD-9 and ICD-10 MI codes into a single list\n",
    "MI_ICD_Codes = pd.concat([icd9_mi, icd10_mi])[\"icd_code\"].unique().tolist()\n",
    "print(\"Myocardial Infarction ICD codes:\", MI_ICD_Codes)\n",
    "\n",
    "#reading the diagnoses_icd zip file in chunks\n",
    "diagnoses_icd = \"diagnoses_icd.csv.gz\"\n",
    "mi_rows = [] #list to store MI related diagnosis rows from each chunk\n",
    "\n",
    "for chunk in pd.read_csv(\n",
    "    diagnoses_icd,\n",
    "    compression=\"gzip\",\n",
    "    chunksize=200_000,  #200,000 records at a time\n",
    "    dtype={\"icd_code\": \"string\"}\n",
    "):\n",
    "    #filtering and storing only MI related rows\n",
    "    mi_chunk = chunk[chunk[\"icd_code\"].isin(MI_ICD_Codes)]\n",
    "    mi_rows.append(mi_chunk)\n",
    "\n",
    "#combining all MI related chunks to a single dataframe\n",
    "mi_diagnoses = pd.concat(mi_rows, ignore_index=True)\n",
    "\n",
    "print(\"\\n\", \"mi_diagnoses\")\n",
    "print(mi_diagnoses.head())\n",
    "print(\"MI diagnosis rows:\", mi_diagnoses.shape[0])\n",
    "print(\"Unique patients:\", mi_diagnoses[\"subject_id\"].nunique())\n",
    "print(\"Unique admissions:\", mi_diagnoses[\"hadm_id\"].nunique())\n",
    "print(mi_diagnoses.shape)\n",
    "\n",
    "df = df.merge(\n",
    "    mi_diagnoses[[\"subject_id\", \"hadm_id\"]].drop_duplicates(),\n",
    "    on=[\"subject_id\", \"hadm_id\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "print(\"\\n\",df.head(10))\n",
    "\n",
    "#below is to print - remove # when needed if not it will print everytime I run it\n",
    "#mi_diagnoses.to_csv(\"mi_diagnoses.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dea262f",
   "metadata": {},
   "source": [
    "3. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06c2600",
   "metadata": {},
   "source": [
    "3.1 Using only the curr_service used at admission - first service per admission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2058d41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "services = services.sort_values([\"subject_id\", \"hadm_id\", \"transfertime\"])\n",
    "\n",
    "services_final = services.drop_duplicates(\n",
    "    subset=[\"subject_id\", \"hadm_id\"],\n",
    "    keep=\"first\"\n",
    ")[[\"subject_id\", \"hadm_id\", \"curr_service\"]]\n",
    "\n",
    "if \"curr_service\" in df.columns:\n",
    "    df = df.drop(columns=[\"curr_service\"])\n",
    "\n",
    "# merge clean curr_service\n",
    "df = df.merge(\n",
    "    services_final,\n",
    "    on=[\"subject_id\", \"hadm_id\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0645b901",
   "metadata": {},
   "source": [
    "3.2 Recording/adding ICD code and version for eaach admission (using seq_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "036a5b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_icd = mi_diagnoses.sort_values([\"subject_id\",\"hadm_id\",\"seq_num\"])\n",
    "\n",
    "mi_icd = mi_icd.drop_duplicates(\n",
    "    subset=[\"subject_id\",\"hadm_id\"]\n",
    ")[[\"subject_id\",\"hadm_id\",\"icd_code\",\"icd_version\"]]\n",
    "\n",
    "df = df.merge(\n",
    "    mi_icd,\n",
    "    on=[\"subject_id\",\"hadm_id\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7405fb",
   "metadata": {},
   "source": [
    "3.3 Dropping duplicate admission rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f8230252",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(\n",
    "    subset=[\"subject_id\",\"hadm_id\"]\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f5138f",
   "metadata": {},
   "source": [
    "3.4 Removing unnecessary rows/ keeping only required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2dc6cfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming anchor_age variable\n",
    "df[\"age\"] = df[\"anchor_age\"]\n",
    "\n",
    "columns = [\n",
    "    \"subject_id\",\n",
    "    \"hadm_id\",\n",
    "    \"admittime\",\n",
    "    \"dischtime\",\n",
    "    \"admission_type\",\n",
    "    \"gender\",\n",
    "    \"age\",\n",
    "    \"curr_service\",\n",
    "    \"icd_code\",\n",
    "    \"icd_version\"\n",
    "]\n",
    "\n",
    "df = df[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddc2b3a",
   "metadata": {},
   "source": [
    "3.5 Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c719a778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEFORE\n",
      "Rows: 16537\n",
      "Unique admissions: 16537\n",
      "\n",
      "AFTER\n",
      "Rows: 16537\n",
      "Unique admissions: 16537\n",
      "\n",
      "Final shape: (16537, 10)\n",
      "\n",
      "    subject_id   hadm_id         admittime         dischtime admission_type  \\\n",
      "0    10000764  27897940  10/14/2132 23:31  10/19/2132 16:30         URGENT   \n",
      "1    10000980  26913865    6/27/2189 7:38     7/3/2189 3:00       EW EMER.   \n",
      "2    10001492  27463908   9/23/2136 18:02   9/25/2136 17:45       EW EMER.   \n",
      "3    10002013  24760295   7/10/2160 19:33   7/12/2160 12:30       EW EMER.   \n",
      "4    10002155  23822395    8/4/2129 12:44   8/18/2129 16:53       EW EMER.   \n",
      "\n",
      "  gender  age curr_service icd_code  icd_version  \n",
      "0      M   86          MED    41071            9  \n",
      "1      F   73          MED    41071            9  \n",
      "2      F   71          MED    41071            9  \n",
      "3      F   53         CMED    41071            9  \n",
      "4      F   80         CMED    41011            9  \n"
     ]
    }
   ],
   "source": [
    "# final checks\n",
    "\n",
    "print(\"\\nBEFORE\")\n",
    "print(\"Rows:\", df.shape[0])\n",
    "print(\"Unique admissions:\", df[[\"subject_id\", \"hadm_id\"]].drop_duplicates().shape[0])\n",
    "\n",
    "#creating final dataset\n",
    "MI_finaldf = df.copy()\n",
    "\n",
    "print(\"\\nAFTER\")\n",
    "print(\"Rows:\", MI_finaldf.shape[0])\n",
    "print(\"Unique admissions:\", MI_finaldf[[\"subject_id\", \"hadm_id\"]].drop_duplicates().shape[0])\n",
    "\n",
    "print(\"\\nFinal shape:\", MI_finaldf.shape)\n",
    "print(\"\\n\", MI_finaldf.head(5))\n",
    "\n",
    "#saving cleaned dataset\n",
    "#MI_finaldf.to_csv(\"MI_finaldf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc445c4",
   "metadata": {},
   "source": [
    "4. Data Engineering/ Variable creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418b0160",
   "metadata": {},
   "source": [
    "4.1 Creating Length of Stay Category (<7 or >7 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9ead631a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            admittime           dischtime  los_days   los_cat\n",
      "0 2132-10-14 23:31:00 2132-10-19 16:30:00       4.7  < 7 days\n",
      "1 2189-06-27 07:38:00 2189-07-03 03:00:00       5.8  < 7 days\n",
      "2 2136-09-23 18:02:00 2136-09-25 17:45:00       2.0  < 7 days\n",
      "3 2160-07-10 19:33:00 2160-07-12 12:30:00       1.7  < 7 days\n",
      "4 2129-08-04 12:44:00 2129-08-18 16:53:00      14.2  ≥ 7 days\n"
     ]
    }
   ],
   "source": [
    "#converting admission and discharge time to datetime format\n",
    "MI_finaldf[\"admittime\"] = pd.to_datetime(MI_finaldf[\"admittime\"])\n",
    "MI_finaldf[\"dischtime\"] = pd.to_datetime(MI_finaldf[\"dischtime\"])\n",
    "\n",
    "#calculating length of stay (LOS) in days\n",
    "MI_finaldf[\"los_days\"] = (\n",
    "    (MI_finaldf[\"dischtime\"] - MI_finaldf[\"admittime\"])\n",
    "    .dt.total_seconds() / (60 * 60 * 24)\n",
    ")\n",
    "MI_finaldf[\"los_days\"] = MI_finaldf[\"los_days\"].round(1)\n",
    "\n",
    "#creating LOS categories:\n",
    "MI_finaldf[\"los_cat\"] = np.where(\n",
    "    MI_finaldf[\"los_days\"] < 7,\n",
    "    \"< 7 days\",\n",
    "    \"≥ 7 days\"\n",
    ")\n",
    "print(MI_finaldf[[\"admittime\", \"dischtime\", \"los_days\", \"los_cat\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8438be9a",
   "metadata": {},
   "source": [
    "4.2 Weekend effect (Weekend/Weekday flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c2d4dd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admit_weekend\n",
      "Weekday    11772\n",
      "Weekend     4765\n",
      "Name: count, dtype: int64\n",
      "\n",
      "              admittime   day_name  dayofweek\n",
      "0  2132-10-14 23:31:00    Tuesday          1\n",
      "1  2189-06-27 07:38:00   Saturday          5\n",
      "2  2136-09-23 18:02:00     Sunday          6\n",
      "3  2160-07-10 19:33:00   Thursday          3\n",
      "4  2129-08-04 12:44:00   Thursday          3\n",
      "5  2141-05-22 20:17:00     Monday          0\n",
      "6  2187-02-23 16:01:00     Friday          4\n",
      "7  2111-01-02 19:21:00     Friday          4\n",
      "8  2166-02-15 13:06:00   Saturday          5\n",
      "9  2125-06-23 18:37:00   Saturday          5\n",
      "10 2132-12-12 01:43:00     Friday          4\n",
      "11 2111-11-13 23:39:00     Friday          4\n",
      "12 2167-11-07 19:05:00   Saturday          5\n",
      "13 2115-12-11 05:24:00  Wednesday          2\n",
      "14 2111-04-12 17:51:00     Sunday          6\n"
     ]
    }
   ],
   "source": [
    "#creating day-of-week variable from admission time (Monday=0, Sunday=6) - check\n",
    "MI_finaldf[\"admit_dayofweek\"] = MI_finaldf[\"admittime\"].dt.dayofweek\n",
    "\n",
    "#creating weekday vs weekend tag\n",
    "MI_finaldf[\"admit_weekend\"] = MI_finaldf[\"admit_dayofweek\"].apply(\n",
    "    lambda x: \"Weekend\" if x >= 5 else \"Weekday\"\n",
    ")\n",
    "\n",
    "#weekday vs weekend count check\n",
    "print(MI_finaldf[\"admit_weekend\"].value_counts())\n",
    "\n",
    "#quick check with actual day names\n",
    "tmp = MI_finaldf[[\"admittime\"]].copy()\n",
    "tmp[\"day_name\"] = MI_finaldf[\"admittime\"].dt.day_name()\n",
    "tmp[\"dayofweek\"] = MI_finaldf[\"admittime\"].dt.dayofweek\n",
    "print(\"\\n\",tmp.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6213a7a6",
   "metadata": {},
   "source": [
    "4.3 Prior MI admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "41d4fad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior_mi\n",
      "N    13152\n",
      "Y     3385\n",
      "Name: count, dtype: int64\n",
      "   subject_id   hadm_id           admittime           dischtime  \\\n",
      "0    10000764  27897940 2132-10-14 23:31:00 2132-10-19 16:30:00   \n",
      "1    10000980  26913865 2189-06-27 07:38:00 2189-07-03 03:00:00   \n",
      "2    10001492  27463908 2136-09-23 18:02:00 2136-09-25 17:45:00   \n",
      "3    10002013  24760295 2160-07-10 19:33:00 2160-07-12 12:30:00   \n",
      "4    10002155  23822395 2129-08-04 12:44:00 2129-08-18 16:53:00   \n",
      "\n",
      "  admission_type gender  age curr_service icd_code  icd_version  los_days  \\\n",
      "0         URGENT      M   86          MED    41071            9       4.7   \n",
      "1       EW EMER.      F   73          MED    41071            9       5.8   \n",
      "2       EW EMER.      F   71          MED    41071            9       2.0   \n",
      "3       EW EMER.      F   53         CMED    41071            9       1.7   \n",
      "4       EW EMER.      F   80         CMED    41011            9      14.2   \n",
      "\n",
      "    los_cat  admit_dayofweek admit_weekend prior_mi  \n",
      "0  < 7 days                1       Weekday        N  \n",
      "1  < 7 days                5       Weekend        N  \n",
      "2  < 7 days                6       Weekend        N  \n",
      "3  < 7 days                3       Weekday        N  \n",
      "4  ≥ 7 days                3       Weekday        N  \n"
     ]
    }
   ],
   "source": [
    "#checking for prior MI admissions\n",
    "MI_finaldf = MI_finaldf.sort_values([\"subject_id\", \"admittime\"]).reset_index(drop=True)\n",
    "MI_finaldf[\"prior_mi\"] = MI_finaldf.groupby(\"subject_id\").cumcount().gt(0).map({True: \"Y\", False: \"N\"})\n",
    "\n",
    "#Quick check\n",
    "print(MI_finaldf[\"prior_mi\"].value_counts(dropna=False))\n",
    "print(MI_finaldf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d068aec",
   "metadata": {},
   "source": [
    "4.4 Other Diagnoses at admission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037f9a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject_id   hadm_id           admittime           dischtime  \\\n",
      "0    10000764  27897940 2132-10-14 23:31:00 2132-10-19 16:30:00   \n",
      "1    10000980  26913865 2189-06-27 07:38:00 2189-07-03 03:00:00   \n",
      "2    10001492  27463908 2136-09-23 18:02:00 2136-09-25 17:45:00   \n",
      "3    10002013  24760295 2160-07-10 19:33:00 2160-07-12 12:30:00   \n",
      "4    10002155  23822395 2129-08-04 12:44:00 2129-08-18 16:53:00   \n",
      "\n",
      "  admission_type gender  age curr_service icd_code  icd_version  los_days  \\\n",
      "0         URGENT      M   86          MED    41071            9       4.7   \n",
      "1       EW EMER.      F   73          MED    41071            9       5.8   \n",
      "2       EW EMER.      F   71          MED    41071            9       2.0   \n",
      "3       EW EMER.      F   53         CMED    41071            9       1.7   \n",
      "4       EW EMER.      F   80         CMED    41011            9      14.2   \n",
      "\n",
      "    los_cat  admit_dayofweek admit_weekend prior_mi  \\\n",
      "0  < 7 days                1       Weekday        N   \n",
      "1  < 7 days                5       Weekend        N   \n",
      "2  < 7 days                6       Weekend        N   \n",
      "3  < 7 days                3       Weekday        N   \n",
      "4  ≥ 7 days                3       Weekday        N   \n",
      "\n",
      "   num_diagnoses_at_admission  \n",
      "0                          18  \n",
      "1                          14  \n",
      "2                           3  \n",
      "3                          14  \n",
      "4                          19  \n"
     ]
    }
   ],
   "source": [
    "hadm_diag_counts = {}\n",
    "\n",
    "for chunk in pd.read_csv(\n",
    "    \"diagnoses_icd.csv.gz\",\n",
    "    compression=\"gzip\",\n",
    "    chunksize=200_000,\n",
    "    usecols=[\"hadm_id\", \"icd_code\"],\n",
    "    dtype={\"icd_code\": \"string\"}\n",
    "):\n",
    "\n",
    "    #excluding MI ICD codes\n",
    "    chunk = chunk[~chunk[\"icd_code\"].isin(MI_ICD_Codes)]\n",
    "\n",
    "    counts = chunk[\"hadm_id\"].value_counts()\n",
    "\n",
    "    for hadm_id, count in counts.items():\n",
    "        hadm_diag_counts[hadm_id] = hadm_diag_counts.get(hadm_id, 0) + count\n",
    "\n",
    "\n",
    "MI_finaldf[\"num_diagnoses_at_admission\"] = (\n",
    "    MI_finaldf[\"hadm_id\"]\n",
    "    .map(hadm_diag_counts)\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "# quick check\n",
    "print(MI_finaldf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d497776b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "#quick check\n",
    "\n",
    "example_id = 27897940\n",
    "\n",
    "count = 0\n",
    "for chunk in pd.read_csv(\n",
    "    \"diagnoses_icd.csv.gz\",\n",
    "    compression=\"gzip\",\n",
    "    chunksize=200_000,\n",
    "    usecols=[\"hadm_id\"]\n",
    "):\n",
    "    count += (chunk[\"hadm_id\"] == example_id).sum()\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbf5cfa",
   "metadata": {},
   "source": [
    "4.5 Readmission group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "66238461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readmission_risk\n",
      "Low       14857\n",
      "High       1420\n",
      "Medium      260\n",
      "Name: count, dtype: int64\n",
      "\n",
      "    subject_id   hadm_id           admittime           dischtime  \\\n",
      "0    10000764  27897940 2132-10-14 23:31:00 2132-10-19 16:30:00   \n",
      "1    10000980  26913865 2189-06-27 07:38:00 2189-07-03 03:00:00   \n",
      "2    10001492  27463908 2136-09-23 18:02:00 2136-09-25 17:45:00   \n",
      "3    10002013  24760295 2160-07-10 19:33:00 2160-07-12 12:30:00   \n",
      "4    10002155  23822395 2129-08-04 12:44:00 2129-08-18 16:53:00   \n",
      "\n",
      "  admission_type gender  age curr_service icd_code  icd_version  los_days  \\\n",
      "0         URGENT      M   86          MED    41071            9       4.7   \n",
      "1       EW EMER.      F   73          MED    41071            9       5.8   \n",
      "2       EW EMER.      F   71          MED    41071            9       2.0   \n",
      "3       EW EMER.      F   53         CMED    41071            9       1.7   \n",
      "4       EW EMER.      F   80         CMED    41011            9      14.2   \n",
      "\n",
      "    los_cat  admit_dayofweek admit_weekend prior_mi  \\\n",
      "0  < 7 days                1       Weekday        N   \n",
      "1  < 7 days                5       Weekend        N   \n",
      "2  < 7 days                6       Weekend        N   \n",
      "3  < 7 days                3       Weekday        N   \n",
      "4  ≥ 7 days                3       Weekday        N   \n",
      "\n",
      "   num_diagnoses_at_admission next_admittime  days_to_readmit readmission_risk  \n",
      "0                          18            NaT              NaN              Low  \n",
      "1                          14            NaT              NaN              Low  \n",
      "2                           3            NaT              NaN              Low  \n",
      "3                          14            NaT              NaN              Low  \n",
      "4                          19            NaT              NaN              Low  \n",
      "(16537, 19)\n"
     ]
    }
   ],
   "source": [
    "#sorting by patient and admission time and getting the next admission time \n",
    "MI_finaldf = MI_finaldf.sort_values([\"subject_id\", \"admittime\"]).reset_index(drop=True)\n",
    "MI_finaldf[\"next_admittime\"] = MI_finaldf.groupby(\"subject_id\")[\"admittime\"].shift(-1)\n",
    "\n",
    "#calculating days from discharge to next MI admission\n",
    "MI_finaldf[\"days_to_readmit\"] = (MI_finaldf[\"next_admittime\"] - MI_finaldf[\"dischtime\"]).dt.days\n",
    "\n",
    "#readmission risk categories\n",
    "MI_finaldf[\"readmission_risk\"] = np.select(\n",
    "    [\n",
    "        MI_finaldf[\"days_to_readmit\"].between(0, 30, inclusive=\"both\"),\n",
    "        MI_finaldf[\"days_to_readmit\"].between(31, 60, inclusive=\"both\"),\n",
    "        (MI_finaldf[\"days_to_readmit\"] > 60) | (MI_finaldf[\"days_to_readmit\"].isna())\n",
    "    ],\n",
    "    [\"High\", \"Medium\", \"Low\"],\n",
    "    default=\"Low\"\n",
    ")\n",
    "\n",
    "#quick check\n",
    "print(MI_finaldf[\"readmission_risk\"].value_counts())\n",
    "print(\"\\n\", MI_finaldf.head())\n",
    "\n",
    "\n",
    "MI_finaldf.to_csv(\"MI_final_dataset.csv\", index=False)\n",
    "\n",
    "print(MI_finaldf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca5e403",
   "metadata": {},
   "source": [
    "5. Modelling and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6a29c4",
   "metadata": {},
   "source": [
    "5.1 Setting predictors and targets - creating a Data frame for Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "dfd55934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 16537\n",
      "Columns: 10\n",
      "\n",
      "Missing values per column:\n",
      "age                           0\n",
      "gender                        0\n",
      "admission_type                0\n",
      "curr_service                  2\n",
      "admit_weekend                 0\n",
      "prior_mi                      0\n",
      "num_diagnoses_at_admission    0\n",
      "los_cat                       0\n",
      "readmission_risk              0\n",
      "subject_id                    0\n",
      "dtype: int64\n",
      "\n",
      "Target distributions:\n",
      "\n",
      "LOS category:\n",
      "los_cat\n",
      "< 7 days    10053\n",
      "≥ 7 days     6484\n",
      "Name: count, dtype: int64\n",
      "\n",
      " readmission_risk\n",
      "Low       14857\n",
      "High       1420\n",
      "Medium      260\n",
      "Name: count, dtype: int64\n",
      "   age gender     admission_type curr_service admit_weekend prior_mi  \\\n",
      "0   86      M             URGENT          MED       Weekday        N   \n",
      "1   73      F           EW EMER.          MED       Weekend        N   \n",
      "2   71      F           EW EMER.          MED       Weekend        N   \n",
      "3   53      F           EW EMER.         CMED       Weekday        N   \n",
      "4   80      F           EW EMER.         CMED       Weekday        N   \n",
      "5   81      M             URGENT         CMED       Weekday        N   \n",
      "6   58      F  OBSERVATION ADMIT        CSURG       Weekday        N   \n",
      "7   91      M  OBSERVATION ADMIT          MED       Weekday        N   \n",
      "8   86      F           EW EMER.          MED       Weekend        N   \n",
      "9   61      M  OBSERVATION ADMIT        CSURG       Weekend        N   \n",
      "\n",
      "   num_diagnoses_at_admission   los_cat readmission_risk  subject_id  \n",
      "0                          18  < 7 days              Low    10000764  \n",
      "1                          14  < 7 days              Low    10000980  \n",
      "2                           3  < 7 days              Low    10001492  \n",
      "3                          14  < 7 days              Low    10002013  \n",
      "4                          19  ≥ 7 days              Low    10002155  \n",
      "5                          25  < 7 days              Low    10002495  \n",
      "6                           8  < 7 days              Low    10002667  \n",
      "7                          12  < 7 days              Low    10003417  \n",
      "8                          12  < 7 days              Low    10003502  \n",
      "9                          20  ≥ 7 days              Low    10005593  \n"
     ]
    }
   ],
   "source": [
    "#predictors\n",
    "predictor_cols = [\n",
    "    \"age\",\n",
    "    \"gender\",\n",
    "    \"admission_type\",\n",
    "    \"curr_service\",\n",
    "    \"admit_weekend\",\n",
    "    \"prior_mi\",\n",
    "    \"num_diagnoses_at_admission\"\n",
    "]\n",
    "\n",
    "# targets\n",
    "target_cols = [\n",
    "    \"los_cat\",\n",
    "    \"readmission_risk\"\n",
    "]\n",
    "\n",
    "#building a separate dataframe for modelling\n",
    "Finalmodel_df = MI_finaldf[predictor_cols + target_cols + [\"subject_id\"]].copy()\n",
    "\n",
    "#quick checks\n",
    "print(\"Rows:\", Finalmodel_df.shape[0])\n",
    "print(\"Columns:\", Finalmodel_df.shape[1])\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(Finalmodel_df.isna().sum())\n",
    "\n",
    "print(\"\\nTarget distributions:\")\n",
    "print(\"\\nLOS category:\")\n",
    "print(Finalmodel_df[\"los_cat\"].value_counts(dropna=False))\n",
    "print('\\n', Finalmodel_df[\"readmission_risk\"].value_counts(dropna=False))\n",
    "print(Finalmodel_df.head(10))\n",
    "\n",
    "#Finalmodel_df.to_csv(\"Finalmodel_df.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "#Finalmodel_df.to_csv(r\"C:\\Users\\User\\Downloads\\MI_final_model_dataset.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "dd009ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Finalmodel_df[\"curr_service\"] = Finalmodel_df[\"curr_service\"].fillna(\"UNKNOWN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2553e4f4",
   "metadata": {},
   "source": [
    "5.2 Creating Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "37943e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 13256 | Test rows: 3281\n",
      "Train patients: 10521 | Test patients: 2631\n",
      "Patient overlap: 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#spliting unique patients into train and test dfs (80/20)\n",
    "train_patients, test_patients = train_test_split(Finalmodel_df[\"subject_id\"].unique(), test_size=0.2, random_state=42)\n",
    "\n",
    "#train/test dataframes using patient split\n",
    "train_df = Finalmodel_df[Finalmodel_df[\"subject_id\"].isin(train_patients)].copy()\n",
    "test_df  = Finalmodel_df[Finalmodel_df[\"subject_id\"].isin(test_patients)].copy()\n",
    "\n",
    "#dropping subject_id from features and creating x y variables for LOS and readmission\n",
    "X_train = train_df.drop(columns=[\"los_cat\", \"readmission_risk\", \"subject_id\"])\n",
    "y_train_los, y_train_readmit = train_df[\"los_cat\"], train_df[\"readmission_risk\"]\n",
    "X_test  = test_df.drop(columns=[\"los_cat\", \"readmission_risk\", \"subject_id\"])\n",
    "y_test_los,  y_test_readmit  = test_df[\"los_cat\"],  test_df[\"readmission_risk\"]\n",
    "\n",
    "#quick checks\n",
    "print(\"Train rows:\", X_train.shape[0], \"| Test rows:\", X_test.shape[0])\n",
    "print(\"Train patients:\", train_df[\"subject_id\"].nunique(), \"| Test patients:\", test_df[\"subject_id\"].nunique())\n",
    "print(\"Patient overlap:\", len(set(train_df[\"subject_id\"]) & set(test_df[\"subject_id\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555d86a7",
   "metadata": {},
   "source": [
    "5.3 Encoding variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda4f19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_enc: (13256, 36) | X_test_enc: (3281, 36)\n",
      "\n",
      "Num features: ['age', 'num_diagnoses_at_admission']\n",
      "\n",
      "First 20 OHE features: ['gender_F' 'gender_M' 'admission_type_AMBULATORY OBSERVATION'\n",
      " 'admission_type_DIRECT EMER.' 'admission_type_DIRECT OBSERVATION'\n",
      " 'admission_type_ELECTIVE' 'admission_type_EU OBSERVATION'\n",
      " 'admission_type_EW EMER.' 'admission_type_OBSERVATION ADMIT'\n",
      " 'admission_type_SURGICAL SAME DAY ADMISSION' 'admission_type_URGENT'\n",
      " 'curr_service_CMED' 'curr_service_CSURG' 'curr_service_ENT'\n",
      " 'curr_service_EYE' 'curr_service_GU' 'curr_service_GYN'\n",
      " 'curr_service_MED' 'curr_service_NMED' 'curr_service_NSURG'\n",
      " 'curr_service_OBS' 'curr_service_OMED' 'curr_service_ORTHO'\n",
      " 'curr_service_PSURG' 'curr_service_PSYCH' 'curr_service_SURG'\n",
      " 'curr_service_TRAUM' 'curr_service_TSURG' 'curr_service_UNKNOWN'\n",
      " 'curr_service_VSURG' 'admit_weekend_Weekday' 'admit_weekend_Weekend'\n",
      " 'prior_mi_N' 'prior_mi_Y']\n",
      "\n",
      "Train LOS distribution:\n",
      "los_cat\n",
      "< 7 days    0.608856\n",
      "≥ 7 days    0.391144\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test LOS distribution:\n",
      "los_cat\n",
      "< 7 days    0.604084\n",
      "≥ 7 days    0.395916\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Train Readmission distribution:\n",
      "readmission_risk\n",
      "Low       0.898537\n",
      "High      0.086150\n",
      "Medium    0.015314\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test Readmission distribution:\n",
      "readmission_risk\n",
      "Low       0.897897\n",
      "High      0.084730\n",
      "Medium    0.017373\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# 1) define categorical + numeric columns (UPDATED)\n",
    "cat_cols = [\"gender\",\"admission_type\",\"curr_service\",\"admit_weekend\",\"prior_mi\"]\n",
    "num_cols = [\"age\", \"num_diagnoses_at_admission\"]\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)\n",
    "\n",
    "X_train_cat = encoder.fit_transform(X_train[cat_cols])\n",
    "X_test_cat  = encoder.transform(X_test[cat_cols])\n",
    "\n",
    "#numeric features\n",
    "X_train_num = X_train[num_cols].astype(float).values\n",
    "X_test_num  = X_test[num_cols].astype(float).values\n",
    "\n",
    "#combining categorical and numeric features into final matrices\n",
    "X_train_enc = hstack([X_train_cat, X_train_num])\n",
    "X_test_enc  = hstack([X_test_cat, X_test_num])\n",
    "\n",
    "print(\"X_train_enc:\", X_train_enc.shape, \"| X_test_enc:\", X_test_enc.shape)\n",
    "\n",
    "#quick checks\n",
    "print(\"\\nNum features:\", num_cols)\n",
    "print(\"\\nFirst 20 OHE features:\", encoder.get_feature_names_out(cat_cols))\n",
    "\n",
    "print(\"\\nTrain LOS distribution:\")\n",
    "print(y_train_los.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nTest LOS distribution:\")\n",
    "print(y_test_los.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nTrain Readmission distribution:\")\n",
    "print(y_train_readmit.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nTest Readmission distribution:\")\n",
    "print(y_test_readmit.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b9bfeb",
   "metadata": {},
   "source": [
    "5.3 Length of Stay Modelling and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cdd4e7",
   "metadata": {},
   "source": [
    "5.3.1 Logisting Regression for LOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "cd6c0412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Logistic Regression - LOS): 0.7577\n",
      "\n",
      "Classification Report (Logistic Regression - LOS):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    < 7 days       0.77      0.86      0.81      1982\n",
      "    ≥ 7 days       0.73      0.61      0.67      1299\n",
      "\n",
      "    accuracy                           0.76      3281\n",
      "   macro avg       0.75      0.73      0.74      3281\n",
      "weighted avg       0.76      0.76      0.75      3281\n",
      "\n",
      "Confusion Matrix (Logistic Regression - LOS):\n",
      " [[1695  287]\n",
      " [ 508  791]]\n",
      "ROC-AUC (Logistic Regression - LOS): 0.8278\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "logreg_los = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "#training the model on training data\n",
    "logreg_los.fit(X_train_enc, y_train_los)\n",
    "\n",
    "#predictions on the test set\n",
    "y_pred_los = logreg_los.predict(X_test_enc)\n",
    "y_prob_los = logreg_los.predict_proba(X_test_enc)[:, 1] #(for ROC-AUC)\n",
    "\n",
    "#evaluation\n",
    "print(\"Accuracy (Logistic Regression - LOS):\", round(accuracy_score(y_test_los, y_pred_los), 4))\n",
    "print(\"\\nClassification Report (Logistic Regression - LOS):\\n\", classification_report(y_test_los, y_pred_los))\n",
    "print(\"Confusion Matrix (Logistic Regression - LOS):\\n\", confusion_matrix(y_test_los, y_pred_los))\n",
    "\n",
    "roc_los = roc_auc_score((y_test_los == \"≥ 7 days\").astype(int), y_prob_los)\n",
    "print(\"ROC-AUC (Logistic Regression - LOS):\", round(roc_los, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565ce2a5",
   "metadata": {},
   "source": [
    "5.3.2 Decision Tree for LOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9085b938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy (Decision Tree - LOS): 0.7098\n",
      "\n",
      "Classification Report (Decision Tree - LOS):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    < 7 days       0.83      0.65      0.73      1982\n",
      "    ≥ 7 days       0.60      0.79      0.68      1299\n",
      "\n",
      "    accuracy                           0.71      3281\n",
      "   macro avg       0.72      0.72      0.71      3281\n",
      "weighted avg       0.74      0.71      0.71      3281\n",
      "\n",
      "Confusion Matrix (Decision Tree - LOS):\n",
      " [[1297  685]\n",
      " [ 267 1032]]\n",
      "ROC-AUC (Decision Tree - LOS): 0.8122\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decisiontree_los = DecisionTreeClassifier(max_depth=5, class_weight=\"balanced\", random_state=42)\n",
    "\n",
    "decisiontree_los.fit(X_train_enc, y_train_los)\n",
    "\n",
    "y_pred_dt = decisiontree_los.predict(X_test_enc)\n",
    "y_prob_dt = decisiontree_los.predict_proba(X_test_enc)[:, 1]\n",
    "\n",
    "print(\"\\n\", \"Accuracy (Decision Tree - LOS):\", round(accuracy_score(y_test_los, y_pred_dt), 4))\n",
    "print(\"\\nClassification Report (Decision Tree - LOS):\\n\", classification_report(y_test_los, y_pred_dt))\n",
    "print(\"Confusion Matrix (Decision Tree - LOS):\\n\", confusion_matrix(y_test_los, y_pred_dt))\n",
    "roc_dt = roc_auc_score((y_test_los == \"≥ 7 days\").astype(int), y_prob_dt)\n",
    "print(\"ROC-AUC (Decision Tree - LOS):\", round(roc_dt, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d35d1d",
   "metadata": {},
   "source": [
    "5.3.3 Random Forest for LOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "689ed079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy (Random Forest - LOS): 0.7351\n",
      "\n",
      "Classification Report (Random Forest - LOS):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    < 7 days       0.83      0.70      0.76      1982\n",
      "    ≥ 7 days       0.63      0.78      0.70      1299\n",
      "\n",
      "    accuracy                           0.74      3281\n",
      "   macro avg       0.73      0.74      0.73      3281\n",
      "weighted avg       0.75      0.74      0.74      3281\n",
      "\n",
      "Confusion Matrix (Random Forest - LOS):\n",
      " [[1393  589]\n",
      " [ 280 1019]]\n",
      "ROC-AUC (Random Forest - LOS): 0.8182\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randomforest_los = RandomForestClassifier( n_estimators=200, max_depth=8, class_weight=\"balanced\",random_state=42)\n",
    "\n",
    "randomforest_los.fit(X_train_enc, y_train_los)\n",
    "\n",
    "y_pred_rf = randomforest_los.predict(X_test_enc)\n",
    "y_prob_rf = randomforest_los.predict_proba(X_test_enc)[:, 1]\n",
    "\n",
    "print(\"\\n\", \"Accuracy (Random Forest - LOS):\", round(accuracy_score(y_test_los, y_pred_rf), 4))\n",
    "print(\"\\nClassification Report (Random Forest - LOS):\\n\", classification_report(y_test_los, y_pred_rf))\n",
    "print(\"Confusion Matrix (Random Forest - LOS):\\n\", confusion_matrix(y_test_los, y_pred_rf))\n",
    "print(\"ROC-AUC (Random Forest - LOS):\", round(roc_auc_score((y_test_los == \"≥ 7 days\").astype(int), y_prob_rf), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f1651c",
   "metadata": {},
   "source": [
    "5.3.4 Gradient Boosting for LOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274755f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Gradient Boosting - LOS): 0.7571\n",
      "\n",
      "Classification Report (Gradient Boosting - LOS):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    < 7 days       0.78      0.84      0.81      1982\n",
      "    ≥ 7 days       0.72      0.63      0.67      1299\n",
      "\n",
      "    accuracy                           0.76      3281\n",
      "   macro avg       0.75      0.74      0.74      3281\n",
      "weighted avg       0.75      0.76      0.75      3281\n",
      "\n",
      "Confusion Matrix (Gradient Boosting - LOS):\n",
      " [[1661  321]\n",
      " [ 476  823]]\n",
      "ROC-AUC (Gradient Boosting - LOS): 0.8283\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gradientboosting_los = GradientBoostingClassifier(n_estimators=200, learning_rate=0.05, max_depth=3, random_state=42)\n",
    "\n",
    "gradientboosting_los.fit(X_train_enc, y_train_los)\n",
    "\n",
    "y_pred_gb = gradientboosting_los.predict(X_test_enc)\n",
    "y_prob_gb = gradientboosting_los.predict_proba(X_test_enc)[:, 1]\n",
    "\n",
    "print(\"Accuracy (Gradient Boosting - LOS):\", round(accuracy_score(y_test_los, y_pred_gb), 4))\n",
    "print(\"\\nClassification Report (Gradient Boosting - LOS):\\n\", classification_report(y_test_los, y_pred_gb))\n",
    "print(\"Confusion Matrix (Gradient Boosting - LOS):\\n\", confusion_matrix(y_test_los, y_pred_gb))\n",
    "print(\"ROC-AUC (Gradient Boosting - LOS):\", round(roc_auc_score((y_test_los == \"≥ 7 days\").astype(int), y_prob_gb), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce2ebab",
   "metadata": {},
   "source": [
    "5.3.5 Cat boost for LOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de22c65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy (CatBoost - LOS): 0.7354\n",
      "\n",
      "Classification Report (CatBoost - LOS):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    < 7 days       0.82      0.73      0.77      1982\n",
      "    ≥ 7 days       0.64      0.75      0.69      1299\n",
      "\n",
      "    accuracy                           0.74      3281\n",
      "   macro avg       0.73      0.74      0.73      3281\n",
      "weighted avg       0.75      0.74      0.74      3281\n",
      "\n",
      "Confusion Matrix (CatBoost - LOS):\n",
      " [[1438  544]\n",
      " [ 324  975]]\n",
      "ROC-AUC (CatBoost - LOS): 0.8229\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "#class weights (balanced) - without extra imports\n",
    "_counts = y_train_los.value_counts()\n",
    "w_short = float(_counts.max() / _counts.get(\"< 7 days\", 1))\n",
    "w_long  = float(_counts.max() / _counts.get(\"≥ 7 days\", 1))\n",
    "\n",
    "catboost_los = CatBoostClassifier(\n",
    "    iterations=800,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    loss_function=\"Logloss\",\n",
    "    class_weights={\n",
    "        \"< 7 days\": w_short,\n",
    "        \"≥ 7 days\": w_long\n",
    "    },\n",
    "    random_seed=42,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "catboost_los.fit(X_train_enc, y_train_los)\n",
    "\n",
    "y_pred_cb = catboost_los.predict(X_test_enc)\n",
    "y_prob_cb = catboost_los.predict_proba(X_test_enc)[:, 1]\n",
    "\n",
    "print(\"\\n\", \"Accuracy (CatBoost - LOS):\", round(accuracy_score(y_test_los, y_pred_cb), 4))\n",
    "print(\"\\nClassification Report (CatBoost - LOS):\\n\", classification_report(y_test_los, y_pred_cb))\n",
    "print(\"Confusion Matrix (CatBoost - LOS):\\n\", confusion_matrix(y_test_los, y_pred_cb))\n",
    "print(\"ROC-AUC (CatBoost - LOS):\", round(roc_auc_score((y_test_los == \"≥ 7 days\").astype(int), y_prob_cb), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917b8007",
   "metadata": {},
   "source": [
    "5.3.6 Support Vector Machine (SVM) for LOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fdd94636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy (SVM - LOS): 0.7257\n",
      "\n",
      "Classification Report (SVM - LOS):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    < 7 days       0.81      0.71      0.76      1982\n",
      "    ≥ 7 days       0.63      0.75      0.68      1299\n",
      "\n",
      "    accuracy                           0.73      3281\n",
      "   macro avg       0.72      0.73      0.72      3281\n",
      "weighted avg       0.74      0.73      0.73      3281\n",
      "\n",
      "Confusion Matrix (SVM - LOS):\n",
      " [[1408  574]\n",
      " [ 326  973]]\n",
      "ROC-AUC (SVM - LOS): 0.8139\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_los = SVC(\n",
    "    kernel=\"rbf\",\n",
    "    C=1.0,\n",
    "    gamma=\"scale\",\n",
    "    class_weight=\"balanced\",\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "svm_los.fit(X_train_enc, y_train_los)\n",
    "\n",
    "y_pred_svm = svm_los.predict(X_test_enc)\n",
    "y_prob_svm = svm_los.predict_proba(X_test_enc)[:, 1]\n",
    "\n",
    "print(\"\\n\", \"Accuracy (SVM - LOS):\", round(accuracy_score(y_test_los, y_pred_svm), 4))\n",
    "print(\"\\nClassification Report (SVM - LOS):\\n\", classification_report(y_test_los, y_pred_svm))\n",
    "print(\"Confusion Matrix (SVM - LOS):\\n\", confusion_matrix(y_test_los, y_pred_svm))\n",
    "print(\"ROC-AUC (SVM - LOS):\", round(roc_auc_score((y_test_los == \"≥ 7 days\").astype(int), y_prob_svm), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2e2ac32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy  Precision  Recall  F1-score  ROC-AUC\n",
      "3    Gradient Boosting    0.7571     0.7194  0.6336    0.6738   0.8283\n",
      "0  Logistic Regression    0.7577     0.7338  0.6089    0.6655   0.8278\n",
      "4             CatBoost    0.7354     0.6419  0.7506    0.6920   0.8229\n",
      "2        Random Forest    0.7351     0.6337  0.7844    0.7011   0.8182\n",
      "5                  SVM    0.7257     0.6290  0.7490    0.6838   0.8139\n",
      "1        Decision Tree    0.7098     0.6010  0.7945    0.6844   0.8122\n"
     ]
    }
   ],
   "source": [
    "# compare all trained models (NO extra imports needed)\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": logreg_los,\n",
    "    \"Decision Tree\": decisiontree_los,\n",
    "    \"Random Forest\": randomforest_los,\n",
    "    \"Gradient Boosting\": gradientboosting_los,\n",
    "    \"CatBoost\": catboost_los,\n",
    "    \"SVM\": svm_los\n",
    "}\n",
    "\n",
    "comparison_results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "\n",
    "    y_pred = model.predict(X_test_enc)\n",
    "    y_prob = model.predict_proba(X_test_enc)[:, 1]\n",
    "\n",
    "    acc = accuracy_score(y_test_los, y_pred)\n",
    "\n",
    "    report = classification_report(y_test_los, y_pred, output_dict=True)\n",
    "\n",
    "    precision = report[\"≥ 7 days\"][\"precision\"]\n",
    "    recall = report[\"≥ 7 days\"][\"recall\"]\n",
    "    f1 = report[\"≥ 7 days\"][\"f1-score\"]\n",
    "\n",
    "    auc = roc_auc_score((y_test_los == \"≥ 7 days\").astype(int), y_prob)\n",
    "\n",
    "    comparison_results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": round(acc, 4),\n",
    "        \"Precision\": round(precision, 4),\n",
    "        \"Recall\": round(recall, 4),\n",
    "        \"F1-score\": round(f1, 4),\n",
    "        \"ROC-AUC\": round(auc, 4)\n",
    "    })\n",
    "\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "comparison_df = comparison_df.sort_values(\"ROC-AUC\", ascending=False)\n",
    "\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3014c32b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bde15f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564ca468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a058b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d29f074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83f30067",
   "metadata": {},
   "source": [
    "Other tests we did - can use below for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b7f0fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "===== Tuned Logistic Regression (LOS) =====\n",
      "Best Params: {'solver': 'liblinear', 'C': 0.01}\n",
      "Best CV F1 (≥7 days): 0.505\n",
      "Accuracy: 0.5285\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    < 7 days       0.65      0.47      0.55      1982\n",
      "    ≥ 7 days       0.43      0.61      0.51      1299\n",
      "\n",
      "    accuracy                           0.53      3281\n",
      "   macro avg       0.54      0.54      0.53      3281\n",
      "weighted avg       0.56      0.53      0.53      3281\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 936 1046]\n",
      " [ 501  798]]\n",
      "ROC-AUC: 0.5464\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter tuning for LR - LOS\n",
    "\n",
    "# --- 1) what we want to optimize: F1 for the long-stay class (\"≥ 7 days\")\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "f1_long = make_scorer(f1_score, pos_label=\"≥ 7 days\")\n",
    "\n",
    "# --- 2) cross-validation setup (runs multiple train/validation splits inside the training set)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# --- 3) hyperparameter search space (these are the \"knobs\" we are tuning)\n",
    "param_lr = {\n",
    "    \"C\": [0.01, 0.05, 0.1, 0.3, 0.5, 1, 2, 5, 10],   # regularization strength\n",
    "    \"solver\": [\"liblinear\", \"lbfgs\"]                  # optimization method\n",
    "}\n",
    "\n",
    "# --- 4) model (base settings)\n",
    "lr_base = LogisticRegression(class_weight=\"balanced\", max_iter=5000, random_state=42)\n",
    "\n",
    "# --- 5) THE TUNING STEP happens here:\n",
    "# RandomizedSearchCV tries many combinations from param_lr using CV, then keeps the best one.\n",
    "lr_search = RandomizedSearchCV(\n",
    "    estimator=lr_base,\n",
    "    param_distributions=param_lr,\n",
    "    n_iter=12,                 # increase for more search (slower); decrease for faster\n",
    "    scoring=f1_long,           # what \"best\" means\n",
    "    refit=True,                # refit best model on full training data at the end\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "lr_search.fit(X_train_enc, y_train_los)\n",
    "\n",
    "# --- 6) best tuned model (this is what you'll use later / save)\n",
    "best_lr = lr_search.best_estimator_\n",
    "\n",
    "# --- 7) evaluate tuned model on test set (same print style you used)\n",
    "y_pred = best_lr.predict(X_test_enc)\n",
    "y_prob = best_lr.predict_proba(X_test_enc)[:, 1]\n",
    "y_test_bin = (y_test_los == \"≥ 7 days\").astype(int)\n",
    "\n",
    "print(\"\\n===== Tuned Logistic Regression (LOS) =====\")\n",
    "print(\"Best Params:\", lr_search.best_params_)\n",
    "print(\"Best CV F1 (≥7 days):\", round(lr_search.best_score_, 4))\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test_los, y_pred), 4))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_los, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_los, y_pred))\n",
    "print(\"ROC-AUC:\", round(roc_auc_score(y_test_bin, y_prob), 4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b447aaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== CatBoost CV (LOS) =====\n",
      "Best Iterations: 26\n",
      "Best CV AUC: 0.5631\n",
      "Accuracy (CatBoost Tuned - LOS): 0.5233\n",
      "\n",
      "Classification Report (CatBoost Tuned - LOS):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    < 7 days       0.65      0.46      0.54      1982\n",
      "    ≥ 7 days       0.43      0.62      0.51      1299\n",
      "\n",
      "    accuracy                           0.52      3281\n",
      "   macro avg       0.54      0.54      0.52      3281\n",
      "weighted avg       0.56      0.52      0.53      3281\n",
      "\n",
      "Confusion Matrix (CatBoost Tuned - LOS):\n",
      " [[ 914 1068]\n",
      " [ 496  803]]\n",
      "ROC-AUC (CatBoost Tuned - LOS): 0.5456\n"
     ]
    }
   ],
   "source": [
    "from catboost import Pool, cv as cb_cv, CatBoostClassifier\n",
    "\n",
    "# binary target for AUC\n",
    "y_train_bin = (y_train_los == \"≥ 7 days\").astype(int)\n",
    "y_test_bin  = (y_test_los  == \"≥ 7 days\").astype(int)\n",
    "\n",
    "train_pool = Pool(X_train_enc, y_train_bin)\n",
    "\n",
    "cb_params = {\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"eval_metric\": \"AUC\",\n",
    "    \"random_seed\": 42,\n",
    "    \"class_weights\": [w_short, w_long],\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"depth\": 6,\n",
    "    \"l2_leaf_reg\": 3,\n",
    "    \"logging_level\": \"Silent\"   # stops fold spam\n",
    "}\n",
    "\n",
    "cv_results = cb_cv(\n",
    "    pool=train_pool,\n",
    "    params=cb_params,\n",
    "    fold_count=5,\n",
    "    iterations=1200,\n",
    "    early_stopping_rounds=50,\n",
    "    shuffle=True,\n",
    "    stratified=True,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "best_iter = int(cv_results[\"test-AUC-mean\"].idxmax() + 1)\n",
    "best_auc  = float(cv_results[\"test-AUC-mean\"].max())\n",
    "\n",
    "best_cb = CatBoostClassifier(\n",
    "    iterations=best_iter,\n",
    "    **cb_params\n",
    ")\n",
    "\n",
    "best_cb.fit(X_train_enc, y_train_bin)\n",
    "\n",
    "y_prob = best_cb.predict_proba(X_test_enc)[:, 1]\n",
    "y_pred_bin = (y_prob >= 0.5).astype(int)\n",
    "y_pred_lbl = np.where(y_pred_bin == 1, \"≥ 7 days\", \"< 7 days\")\n",
    "\n",
    "print(\"\\n===== CatBoost CV (LOS) =====\")\n",
    "print(\"Best Iterations:\", best_iter)\n",
    "print(\"Best CV AUC:\", round(best_auc, 4))\n",
    "print(\"Accuracy (CatBoost Tuned - LOS):\", round(accuracy_score(y_test_los, y_pred_lbl), 4))\n",
    "print(\"\\nClassification Report (CatBoost Tuned - LOS):\\n\", classification_report(y_test_los, y_pred_lbl))\n",
    "print(\"Confusion Matrix (CatBoost Tuned - LOS):\\n\", confusion_matrix(y_test_los, y_pred_lbl))\n",
    "print(\"ROC-AUC (CatBoost Tuned - LOS):\", round(roc_auc_score(y_test_bin, y_prob), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ada01a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "===== Tuned SVM (LOS) =====\n",
      "Best Params: {'kernel': 'rbf', 'gamma': 0.01, 'C': 0.1}\n",
      "Best CV F1 (≥7 days): 0.5469\n",
      "Accuracy: 0.4505\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    < 7 days       0.62      0.23      0.34      1982\n",
      "    ≥ 7 days       0.40      0.79      0.53      1299\n",
      "\n",
      "    accuracy                           0.45      3281\n",
      "   macro avg       0.51      0.51      0.43      3281\n",
      "weighted avg       0.53      0.45      0.41      3281\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 456 1526]\n",
      " [ 277 1022]]\n",
      "ROC-AUC: 0.5413\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Hyperparameter tuning (LOS) - SVM ONLY (FAST)\n",
    "# =========================\n",
    "\n",
    "param_svm = {\n",
    "    \"C\": [0.1, 0.3, 0.5, 1, 2, 5, 10],\n",
    "    \"gamma\": [\"scale\", 0.01, 0.05, 0.1],\n",
    "    \"kernel\": [\"rbf\"]   # keep only rbf for speed\n",
    "}\n",
    "\n",
    "svm_base = SVC(\n",
    "    class_weight=\"balanced\",\n",
    "    probability=False,   # faster tuning\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "svm_search = RandomizedSearchCV(\n",
    "    estimator=svm_base,\n",
    "    param_distributions=param_svm,\n",
    "    n_iter=12,\n",
    "    scoring=f1_long,\n",
    "    refit=True,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "svm_search.fit(X_train_enc, y_train_los)\n",
    "\n",
    "# retrain final SVM with probability=True for ROC-AUC\n",
    "best_svm = SVC(\n",
    "    **svm_search.best_params_,\n",
    "    class_weight=\"balanced\",\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "best_svm.fit(X_train_enc, y_train_los)\n",
    "\n",
    "# evaluate\n",
    "y_pred = best_svm.predict(X_test_enc)\n",
    "y_prob = best_svm.predict_proba(X_test_enc)[:, 1]\n",
    "\n",
    "print(\"\\n===== Tuned SVM (LOS) =====\")\n",
    "print(\"Best Params:\", svm_search.best_params_)\n",
    "print(\"Best CV F1 (≥7 days):\", round(svm_search.best_score_, 4))\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test_los, y_pred), 4))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_los, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_los, y_pred))\n",
    "print(\"ROC-AUC:\", round(roc_auc_score(y_test_bin, y_prob), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72532a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Top 20 Other Diagnoses (non-MI) in MI admissions =====\n",
      "  5822  Hyperlipidemia, unspecified\n",
      "  5420  Atherosclerotic heart disease of native coronary artery without angina pectoris\n",
      "  4883  Coronary atherosclerosis of native coronary artery\n",
      "  4672  Acute kidney failure, unspecified\n",
      "  3646  Personal history of nicotine dependence\n",
      "  3431  Other and unspecified hyperlipidemia\n",
      "  3318  Unspecified essential hypertension\n",
      "  2884  Congestive heart failure, unspecified\n",
      "  2780  Essential (primary) hypertension\n",
      "  2700  Gastro-esophageal reflux disease without esophagitis\n",
      "  2504  Acute posthemorrhagic anemia\n",
      "  2289  Old myocardial infarction\n",
      "  2185  Chronic kidney disease, unspecified\n",
      "  2105  Acidosis\n",
      "  2038  Anemia, unspecified\n",
      "  2037  Long term (current) use of insulin\n",
      "  1941  Type 2 diabetes mellitus with diabetic chronic kidney disease\n",
      "  1854  Long term (current) use of antithrombotics/antiplatelets\n",
      "  1833  Urinary tract infection, site not specified\n",
      "  1828  Do not resuscitate\n"
     ]
    }
   ],
   "source": [
    "# --- 0) make sure the dictionary table is loaded (if not already)\n",
    "d_icd_diagnoses = pd.read_csv(\"d_icd_diagnoses.csv/d_icd_diagnoses.csv\")\n",
    "\n",
    "# --- 1) MI admissions lookup (admission-level)\n",
    "mi_keys = set(zip(MI_finaldf[\"subject_id\"], MI_finaldf[\"hadm_id\"]))\n",
    "\n",
    "# --- 2) quick dict: (icd_code, icd_version) -> long_title\n",
    "d_icd_diagnoses[\"icd_code\"] = d_icd_diagnoses[\"icd_code\"].astype(str).str.replace(\".\", \"\", regex=False)\n",
    "icd_map = dict(zip(\n",
    "    zip(d_icd_diagnoses[\"icd_code\"], d_icd_diagnoses[\"icd_version\"]),\n",
    "    d_icd_diagnoses[\"long_title\"]\n",
    "))\n",
    "\n",
    "# --- 3) count top other diagnoses (non-MI) among MI admissions (chunked)\n",
    "from collections import Counter\n",
    "title_counts = Counter()\n",
    "\n",
    "for chunk in pd.read_csv(\n",
    "    \"diagnoses_icd.csv.gz\",\n",
    "    compression=\"gzip\",\n",
    "    usecols=[\"subject_id\", \"hadm_id\", \"icd_code\", \"icd_version\"],\n",
    "    dtype={\"icd_code\": \"string\"},\n",
    "    chunksize=500_000\n",
    "):\n",
    "    chunk[\"icd_code\"] = chunk[\"icd_code\"].str.replace(\".\", \"\", regex=False)\n",
    "\n",
    "    # keep only MI admissions\n",
    "    in_mi = list(zip(chunk[\"subject_id\"], chunk[\"hadm_id\"]))\n",
    "    sub = chunk[[k in mi_keys for k in in_mi]].copy()\n",
    "    if sub.empty:\n",
    "        continue\n",
    "\n",
    "    # remove MI codes\n",
    "    is_mi = (\n",
    "        ((sub[\"icd_version\"] == 9) & sub[\"icd_code\"].str.startswith(\"410\")) |\n",
    "        ((sub[\"icd_version\"] == 10) & (sub[\"icd_code\"].str.startswith(\"I21\") | sub[\"icd_code\"].str.startswith(\"I22\")))\n",
    "    )\n",
    "    sub = sub[~is_mi]\n",
    "    if sub.empty:\n",
    "        continue\n",
    "\n",
    "    # map to titles + count\n",
    "    for code, ver in zip(sub[\"icd_code\"].astype(str), sub[\"icd_version\"].astype(int)):\n",
    "        title_counts[icd_map.get((code, ver), f\"UNKNOWN_{ver}_{code}\")] += 1\n",
    "\n",
    "# --- 4) print top 20\n",
    "print(\"\\n===== Top 20 Other Diagnoses (non-MI) in MI admissions =====\")\n",
    "for title, cnt in title_counts.most_common(20):\n",
    "    print(f\"{cnt:>6}  {title}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
